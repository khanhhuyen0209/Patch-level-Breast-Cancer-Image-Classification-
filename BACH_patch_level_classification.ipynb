{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEEaUrtP1aFC"
      },
      "source": [
        "**Link DRIVE với COLAB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYNOhwiZnUxb",
        "outputId": "ade2c944-485c-488f-cada-d1b5450affbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UF3xsGdAU2p",
        "outputId": "cd69a150-3601-4613-d401-67f8900d3f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giải nén xong trong /content/BACH_raw\n",
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Dec 15 22:02 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 15 22:02 ..\n",
            "drwxr-xr-x 4 root root 4096 Dec 15 22:02 main_folder\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/BACH/archive.zip\"\n",
        "extract_path = \"/content/BACH_raw\"\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_path)\n",
        "\n",
        "print(\"Giải nén xong trong /content/BACH_raw\")\n",
        "!ls -la /content/BACH_raw | head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tY8yG2PeeTG"
      },
      "source": [
        "**Cài thư viện cần thiết (chỉ chạy 1 lần / notebook mới)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcL5S4PNeb_w"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-image scikit-learn opencv-python tqdm split-folders albumentations\n",
        "!pip install -q torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S02_RHX-mc7O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import gc\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import ToPILImage\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import shutil\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage import io, transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0K1KaUalXl6"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    patch_size = 512\n",
        "    overlap = 0.5\n",
        "    batch_size = 16 # 4-> 8\n",
        "    num_epochs = 25\n",
        "    learning_rate = 3e-5\n",
        "    num_classes = 4\n",
        "    use_macenko = True\n",
        "    early_normal_ratio = 0.12   # nếu ratio patches informative < 12%, gán Normal\n",
        "    unsup_mean_thresh = 0.9\n",
        "    unsup_var_thresh = 0.005\n",
        "    unsup_edge_thresh = 0.02\n",
        "    mean = np.array([0.84263392, 0.6172471, 0.71754202])\n",
        "    std = np.array([0.11667027, 0.18648461, 0.16371168])\n",
        "    dropout_rate = 0.3 # Added for regularization\n",
        "    num_workers = 2 # Added for faster data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8pRaFfqMJ36"
      },
      "source": [
        "### **DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b3fcb5d"
      },
      "outputs": [],
      "source": [
        "# Remove old intermediate patch directory if it exists\n",
        "shutil.rmtree(\"/content/BACH_processed_patches\", ignore_errors=True)\n",
        "\n",
        "# Define paths for training and validation data\n",
        "TRAIN_VAL_RAW_PATH = \"/content/BACH_raw/main_folder/train_folder\"\n",
        "\n",
        "# Define paths for test data\n",
        "TEST_RAW_PATH = \"/content/BACH_raw/main_folder/testing_folder\"\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/model\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTnHS6sDK-OY"
      },
      "outputs": [],
      "source": [
        "data_dir = TRAIN_VAL_RAW_PATH\n",
        "\n",
        "image_paths, labels = [], []\n",
        "class_names = sorted(os.listdir(data_dir))\n",
        "\n",
        "# Define common image extensions to filter files\n",
        "IMAGE_EXTENSIONS = ('.png', '.jpg', '.jpeg', '.tif', '.tiff')\n",
        "\n",
        "for label, cls in enumerate(class_names):\n",
        "    cls_dir = os.path.join(data_dir, cls)\n",
        "    for f in os.listdir(cls_dir):\n",
        "        # Filter out non-image files like .ipynb_checkpoints\n",
        "        if not f.lower().endswith(IMAGE_EXTENSIONS):\n",
        "            # print(f\"Skipping non-image file/directory: {os.path.join(cls_dir, f)}\") # Optionally print what's skipped\n",
        "            continue\n",
        "        image_paths.append(os.path.join(cls_dir, f))\n",
        "        labels.append(label)\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c11d3e3",
        "outputId": "68d58914-6f0f-44c5-9d50-98307b036cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 320\n",
            "Validation images: 80\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets (80-20 split)\n",
        "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"Train images: {len(train_image_paths)}\")\n",
        "print(f\"Validation images: {len(val_image_paths)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCTg7-6K6U_"
      },
      "source": [
        "### Patch tiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBNUxix3OBc6"
      },
      "outputs": [],
      "source": [
        "def tile_image(img, patch_size=512, overlap=0.5):\n",
        "    stride = int(patch_size * (1 - overlap))\n",
        "    patches = []\n",
        "    h, w, _ = img.shape\n",
        "    for y in range(0, h - patch_size + 1, stride):\n",
        "        for x in range(0, w - patch_size + 1, stride):\n",
        "            patch = img[y:y+patch_size, x:x+patch_size]\n",
        "            patches.append(patch)\n",
        "    return patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ORKIfmn-JPc"
      },
      "source": [
        "### Macenko Stain Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hkg-ueG9GiF"
      },
      "outputs": [],
      "source": [
        "def rgb2od(I):\n",
        "    I = np.asarray(I, dtype=np.float32)\n",
        "    I = np.maximum(I, 1) / 255.0\n",
        "    OD = -np.log(I)\n",
        "    return OD\n",
        "\n",
        "def od2rgb(OD):\n",
        "    OD = np.clip(OD, 0, 5)\n",
        "    I = 255 * np.exp(-OD)\n",
        "    return np.clip(I, 0, 255).astype(np.uint8)\n",
        "\n",
        "def macenko_normalize(img, alpha=1.0, beta=0.15):\n",
        "    OD = rgb2od(img).reshape((-1, 3))\n",
        "\n",
        "    # Remove background\n",
        "    OD_hat = OD[(OD > beta).any(axis=1)]\n",
        "    if OD_hat.shape[0] < 10:\n",
        "        return img\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    pca.fit(OD_hat)\n",
        "    V = pca.components_\n",
        "\n",
        "    # Project\n",
        "    C = np.dot(OD, V.T)\n",
        "\n",
        "    # non-negative concentration\n",
        "    C = np.maximum(C, 0)\n",
        "\n",
        "    # Normalize concentration\n",
        "    max_C = np.percentile(C, 99, axis=0)\n",
        "    C_normalized = C / (max_C + 1e-8)\n",
        "\n",
        "    # Reconstruct\n",
        "    OD_norm = np.dot(C_normalized, V)\n",
        "    OD_norm = np.maximum(OD_norm, 0)\n",
        "    OD_norm = OD_norm.reshape(img.shape)\n",
        "\n",
        "    return od2rgb(OD_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy7ASXdzPKui"
      },
      "outputs": [],
      "source": [
        "def get_transforms(mean, std):\n",
        "    train_tf = T.Compose([\n",
        "        ToPILImage(),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomVerticalFlip(),\n",
        "        T.RandomRotation(20),\n",
        "        T.ColorJitter(0.2,0.2,0.2),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean, std)\n",
        "    ])\n",
        "\n",
        "    val_tf = T.Compose([\n",
        "        ToPILImage(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean, std)\n",
        "    ])\n",
        "    return train_tf, val_tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce0hvzA_L3lK"
      },
      "outputs": [],
      "source": [
        "def split_patches_advanced(patches, mean_thresh=0.9, var_thresh=0.005, edge_thresh=0.02):\n",
        "    informative, non_informative = [], []\n",
        "    for p in patches:\n",
        "        p_norm = p / 255.0\n",
        "        mean_intensity = p_norm.mean()\n",
        "        var_intensity = p_norm.var()\n",
        "        edges = cv2.Canny((p_norm*255).astype(np.uint8), 50,150)\n",
        "        edge_ratio = edges.sum() / (p.shape[0]*p.shape[1]*255)\n",
        "        if (mean_intensity < mean_thresh) and (var_intensity > var_thresh) and (edge_ratio > edge_thresh):\n",
        "            informative.append(p)\n",
        "        else:\n",
        "            non_informative.append(p)\n",
        "    return informative, non_informative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H4RiOYqL4v1"
      },
      "outputs": [],
      "source": [
        "def early_normal_check(img_path):\n",
        "    img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    if config.use_macenko:\n",
        "        img = macenko_normalize(img)\n",
        "    patches = tile_image(img, config.patch_size, config.overlap)\n",
        "    informative, _ = split_patches_advanced(\n",
        "        patches, config.unsup_mean_thresh, config.unsup_var_thresh, config.unsup_edge_thresh\n",
        "    )\n",
        "    ratio = len(informative)/len(patches)\n",
        "    is_early_normal = ratio < config.early_normal_ratio\n",
        "    return is_early_normal, ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQuiW_RxL-XA"
      },
      "outputs": [],
      "source": [
        "def show_patch_bag(img_path, n_cols=6):\n",
        "    img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    if config.use_macenko:\n",
        "        img = macenko_normalize(img)\n",
        "    patches = tile_image(img, config.patch_size, config.overlap)\n",
        "    informative, non_informative = split_patches_advanced(\n",
        "        patches, config.unsup_mean_thresh, config.unsup_var_thresh, config.unsup_edge_thresh\n",
        "    )\n",
        "    print(f\"Total patches: {len(patches)}, Informative: {len(informative)}\")\n",
        "    display_patches = informative[:n_cols*n_cols]\n",
        "    n_display = len(display_patches)\n",
        "    n_rows = (n_display + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*2, n_rows*2))\n",
        "    axes = axes.flatten()\n",
        "    for i in range(n_display):\n",
        "        axes[i].imshow(display_patches[i])\n",
        "        axes[i].axis(\"off\")\n",
        "    for i in range(n_display, len(axes)):\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzCv-SzaWG5G"
      },
      "source": [
        "### Dataset cho train/val datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0IB4mR1-UuS"
      },
      "outputs": [],
      "source": [
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        for img_path, label in zip(image_paths, labels):\n",
        "            is_normal, ratio = early_normal_check(img_path)\n",
        "            # Nếu early normal → gán Normal luôn, bỏ patch-level training\n",
        "            if is_normal:\n",
        "                self.data.append(None)\n",
        "                self.targets.append(0)\n",
        "            else:\n",
        "                img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "                if config.use_macenko:\n",
        "                    img = macenko_normalize(img)\n",
        "                patches = tile_image(img, config.patch_size, config.overlap)\n",
        "                informative, _ = split_patches_advanced(\n",
        "                    patches, config.unsup_mean_thresh, config.unsup_var_thresh, config.unsup_edge_thresh\n",
        "                )\n",
        "                for p in informative:\n",
        "                    self.data.append(p)\n",
        "                    self.targets.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patch = self.data[idx]\n",
        "        label = self.targets[idx]\n",
        "        if patch is None:  # early normal\n",
        "            return torch.zeros(3, config.patch_size, config.patch_size), torch.tensor(label)\n",
        "        if self.transform:\n",
        "            patch = self.transform(patch)\n",
        "        return patch, torch.tensor(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-NktFQ6JmlY"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPYm1jlFJoZw"
      },
      "outputs": [],
      "source": [
        "train_tf, val_tf = get_transforms(config.mean, config.std)\n",
        "\n",
        "train_dataset = PatchDataset(\n",
        "    train_image_paths, train_labels,\n",
        "    transform=train_tf,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=config.num_workers # Added num_workers\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLgAjpqlMfZE",
        "outputId": "f2d1b769-3882-4540-a923-279ebdb36960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 158MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify the classifier to include dropout and the new number of classes\n",
        "# The EfficientNet_B0_Weights.IMAGENET1K_V1 already includes a Dropout layer at index 0\n",
        "# We will replace both the dropout and the linear layer to ensure correct configuration.\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=config.dropout_rate), # Apply dropout with configurable rate\n",
        "    nn.Linear(model.classifier[1].in_features, config.num_classes)\n",
        ")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GkJC1PeMiI1"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "    for imgs, labels in dataloader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()*imgs.size(0)\n",
        "        _, preds = torch.max(outputs,1)\n",
        "        correct += (preds==labels).sum().item()\n",
        "        total += imgs.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0,0,0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()*imgs.size(0)\n",
        "            _, preds = torch.max(outputs,1)\n",
        "            correct += (preds==labels).sum().item()\n",
        "            total += imgs.size(0)\n",
        "    return running_loss/total, correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZVkbxB5LCYL"
      },
      "outputs": [],
      "source": [
        "def predict_image_label(model, img_path):\n",
        "    img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    if config.use_macenko:\n",
        "        img = macenko_normalize(img)\n",
        "    patches = tile_image(img, config.patch_size, config.overlap)\n",
        "    informative, _ = split_patches_advanced(\n",
        "        patches, config.unsup_mean_thresh, config.unsup_var_thresh, config.unsup_edge_thresh\n",
        "    )\n",
        "    if len(informative)/len(patches) < config.early_normal_ratio:\n",
        "        return 0  # early normal\n",
        "\n",
        "    model.eval()\n",
        "    evidence_sum = torch.zeros(config.num_classes)\n",
        "    with torch.no_grad():\n",
        "        for p in informative:\n",
        "            p_tensor = val_tf(p).unsqueeze(0).to(device) # Changed to val_tf\n",
        "            logits = model(p_tensor)\n",
        "            e = torch.exp(logits.squeeze())\n",
        "            evidence_sum += e.cpu()\n",
        "    return torch.argmax(evidence_sum).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57vSBwNhM6PM",
        "outputId": "3aff6d2b-5b9a-4599-b861-7006b2720a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 | Train Loss: 0.4854 | Train Acc: 0.8176 | Val Accuracy: 0.8250\n",
            "-> Best model saved with Val Accuracy: 0.8250\n",
            "Epoch 2/25 | Train Loss: 0.3365 | Train Acc: 0.8750 | Val Accuracy: 0.8375\n",
            "-> Best model saved with Val Accuracy: 0.8375\n",
            "Epoch 3/25 | Train Loss: 0.2557 | Train Acc: 0.9078 | Val Accuracy: 0.8125\n",
            "Epoch 4/25 | Train Loss: 0.2002 | Train Acc: 0.9291 | Val Accuracy: 0.8125\n",
            "Epoch 5/25 | Train Loss: 0.1673 | Train Acc: 0.9415 | Val Accuracy: 0.8125\n",
            "Epoch 6/25 | Train Loss: 0.1454 | Train Acc: 0.9514 | Val Accuracy: 0.8625\n",
            "-> Best model saved with Val Accuracy: 0.8625\n",
            "Epoch 7/25 | Train Loss: 0.1287 | Train Acc: 0.9551 | Val Accuracy: 0.8250\n",
            "Epoch 8/25 | Train Loss: 0.1125 | Train Acc: 0.9623 | Val Accuracy: 0.8375\n",
            "Epoch 9/25 | Train Loss: 0.0976 | Train Acc: 0.9675 | Val Accuracy: 0.8250\n",
            "Epoch 10/25 | Train Loss: 0.0882 | Train Acc: 0.9723 | Val Accuracy: 0.8500\n",
            "Epoch 11/25 | Train Loss: 0.0774 | Train Acc: 0.9752 | Val Accuracy: 0.8500\n",
            "Epoch 12/25 | Train Loss: 0.0760 | Train Acc: 0.9755 | Val Accuracy: 0.8875\n",
            "-> Best model saved with Val Accuracy: 0.8875\n",
            "Epoch 13/25 | Train Loss: 0.0691 | Train Acc: 0.9768 | Val Accuracy: 0.8625\n",
            "Epoch 14/25 | Train Loss: 0.0560 | Train Acc: 0.9819 | Val Accuracy: 0.9000\n",
            "-> Best model saved with Val Accuracy: 0.9000\n",
            "Epoch 15/25 | Train Loss: 0.0542 | Train Acc: 0.9816 | Val Accuracy: 0.8625\n",
            "Epoch 16/25 | Train Loss: 0.0552 | Train Acc: 0.9837 | Val Accuracy: 0.8250\n",
            "Epoch 17/25 | Train Loss: 0.0532 | Train Acc: 0.9832 | Val Accuracy: 0.8750\n",
            "Epoch 18/25 | Train Loss: 0.0440 | Train Acc: 0.9863 | Val Accuracy: 0.8500\n",
            "Epoch 19/25 | Train Loss: 0.0360 | Train Acc: 0.9885 | Val Accuracy: 0.8500\n",
            "Epoch 20/25 | Train Loss: 0.0378 | Train Acc: 0.9887 | Val Accuracy: 0.8250\n",
            "Epoch 21/25 | Train Loss: 0.0344 | Train Acc: 0.9908 | Val Accuracy: 0.8750\n",
            "Epoch 22/25 | Train Loss: 0.0313 | Train Acc: 0.9903 | Val Accuracy: 0.8500\n",
            "Epoch 23/25 | Train Loss: 0.0325 | Train Acc: 0.9898 | Val Accuracy: 0.8500\n",
            "Epoch 24/25 | Train Loss: 0.0277 | Train Acc: 0.9910 | Val Accuracy: 0.8625\n",
            "Epoch 25/25 | Train Loss: 0.0289 | Train Acc: 0.9898 | Val Accuracy: 0.8500\n",
            "Training complete. Best val accuracy: 0.9000, model saved at /content/drive/MyDrive/model/best_patch_model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# ==============================\n",
        "# Model, optimizer, criterion\n",
        "# ==============================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "# ==============================\n",
        "# Training loop\n",
        "# ==============================\n",
        "best_val_acc = 0\n",
        "best_model_path = os.path.join(out_dir, \"best_patch_model.pth\")\n",
        "\n",
        "for epoch in range(config.num_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "\n",
        "    # Evaluate image-level on val set\n",
        "    correct_img, total_img = 0, 0\n",
        "    for img_path, true_label in zip(val_image_paths, val_labels):\n",
        "        pred_label = predict_image_label(model, img_path)\n",
        "        if pred_label == true_label:\n",
        "            correct_img +=1\n",
        "        total_img +=1\n",
        "    val_acc = correct_img / total_img\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{config.num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"-> Best model saved with Val Accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "print(f\"Training complete. Best val accuracy: {best_val_acc:.4f}, model saved at {best_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc2kQxdkLIVp"
      },
      "source": [
        "### Load best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDn_QlF6LKnv",
        "outputId": "4d987420-3f87-4fed-bf5d-0bb4390d50c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.3, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "best_model_path = \"/content/drive/MyDrive/model/best_patch_model.pth\"\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYYe9PgtLN95"
      },
      "source": [
        "### TEST + EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CGoe2imLTM1"
      },
      "outputs": [],
      "source": [
        "test_image_paths = []\n",
        "test_labels = []\n",
        "\n",
        "class_names = sorted(os.listdir(TEST_RAW_PATH))\n",
        "for label, cls in enumerate(class_names):\n",
        "    cls_dir = os.path.join(TEST_RAW_PATH, cls)\n",
        "    for f in os.listdir(cls_dir):\n",
        "        if f.lower().endswith(IMAGE_EXTENSIONS):\n",
        "            test_image_paths.append(os.path.join(cls_dir, f))\n",
        "            test_labels.append(label)\n",
        "\n",
        "test_dataset = PatchDataset(\n",
        "    test_image_paths, test_labels,\n",
        "    transform=val_tf,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=config.num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdXqhL59LVxL"
      },
      "source": [
        "### Test accuracy + confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "d_xMeKEFLZtZ",
        "outputId": "18adb72b-3547-4289-9a65-b6bbd3c0254c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 77/77 [00:13<00:00,  5.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9357723577235773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       1.00      0.88      0.94       321\n",
            "      InSitu       0.90      1.00      0.94       350\n",
            "    Invasive       0.98      0.90      0.94       309\n",
            "      Normal       0.88      0.97      0.92       250\n",
            "\n",
            "    accuracy                           0.94      1230\n",
            "   macro avg       0.94      0.94      0.93      1230\n",
            "weighted avg       0.94      0.94      0.94      1230\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_model_patch(model, loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for patches, labels in tqdm(loader):\n",
        "        patches, labels = patches.to(device), labels.to(device)\n",
        "        logits = model(patches) # Model outputs only logits\n",
        "        preds = logits.argmax(dim=1) # Get predictions for the entire batch\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy()) # Extend with true labels from batch\n",
        "        y_pred.extend(preds.cpu().numpy())  # Extend with predicted labels from batch\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred)\n",
        "\n",
        "def test_model_image(model,  image_paths, true_labels):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for img_path, true_label in tqdm(zip(image_paths, true_labels), total=len(image_paths)):\n",
        "        pred_label = predict_image_label(model, img_path)\n",
        "        y_true.append(true_label)\n",
        "        y_pred.append(pred_label)\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred)\n",
        "\n",
        "# ===== RUN TEST =====\n",
        "y_true_patch, y_pred_patch = test_model_patch(model, test_loader)\n",
        "y_true_image, y_pred_image = test_model_image(model, test_image_paths, test_labels)\n",
        "\n",
        "# ===== Accuracy =====\n",
        "print(\"Test Accuracy:\", (y_true_patch == y_pred_patch).mean())\n",
        "print(\"Test Accuracy:\", (y_true_image == y_pred_image).mean())\n",
        "\n",
        "# ===== Confusion Matrix =====\n",
        "cm = confusion_matrix(y_true_patch, y_pred_patch)\n",
        "\n",
        "plt.figure()\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=class_names\n",
        ")\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix Patch Level\")\n",
        "plt.show()\n",
        "\n",
        "cm1 = confusion_matrix(y_true_image, y_pred_image)\n",
        "\n",
        "plt.figure()\n",
        "disp1 = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm1,\n",
        "    display_labels=class_names\n",
        ")\n",
        "disp1.plot()\n",
        "plt.title(\"Confusion Matrix Image Level\")\n",
        "plt.show()\n",
        "# ===== Classification Report =====\n",
        "print(classification_report(y_true_patch, y_pred_patch, target_names=class_names))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}